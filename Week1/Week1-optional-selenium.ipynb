{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1 (Optional): Web Scraping with Selenium\n",
    "\n",
    "**Web and Social Network Analytics**\n",
    "\n",
    "---\n",
    "\n",
    "**Note**: This notebook is **optional** supplementary material. The main notebook (`Week1-notes.ipynb`) covers Playwright, which is recommended for JupyterHub environments. Use this notebook if:\n",
    "\n",
    "- You're working on your **local machine**\n",
    "- You need to learn Selenium for work/research (industry standard)\n",
    "- You want to compare Selenium vs Playwright approaches\n",
    "\n",
    "---\n",
    "\n",
    "**Disclaimer**: This educational content is provided for instructional purposes only. Always respect website terms of service and legal requirements when scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to Use Selenium vs Playwright\n",
    "\n",
    "| Feature | Selenium | Playwright |\n",
    "|---------|----------|------------|\n",
    "| **Browser Support** | Chrome, Firefox, Safari, Edge | Chromium, Firefox, WebKit |\n",
    "| **Setup Complexity** | Requires matching driver version | Auto-manages browsers |\n",
    "| **Industry Adoption** | Very widely used | Growing rapidly |\n",
    "| **Documentation** | Extensive, many tutorials | Modern, well-organized |\n",
    "| **Virtual Environments** | Can be tricky | Works well |\n",
    "| **Async Support** | Limited | Built-in |\n",
    "\n",
    "**Recommendation**: \n",
    "- Use **Playwright** for new projects and virtual environments\n",
    "- Learn **Selenium** if you'll work with existing codebases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Setting Up Selenium\n",
    "\n",
    "## Step 1: Install Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install\n",
    "# !pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Download ChromeDriver\n",
    "\n",
    "Selenium needs a **WebDriver** to control the browser. For Chrome:\n",
    "\n",
    "### 2.1 Find Your Chrome Version\n",
    "\n",
    "1. Open Chrome\n",
    "2. Go to `chrome://settings/help`\n",
    "3. Note the version number (e.g., `131.0.6778.265`)\n",
    "\n",
    "### 2.2 Download Matching ChromeDriver\n",
    "\n",
    "**For Chrome version 115 or newer:**\n",
    "- Go to [Chrome for Testing](https://googlechromelabs.github.io/chrome-for-testing/)\n",
    "- Find the \"chromedriver\" row matching your Chrome version\n",
    "- Download for your OS (win64, mac-x64, mac-arm64, linux64)\n",
    "\n",
    "**For Chrome version 114 or older:**\n",
    "- Go to [ChromeDriver Downloads](https://chromedriver.storage.googleapis.com/index.html)\n",
    "- Find your version folder\n",
    "- Download the appropriate zip file\n",
    "\n",
    "### 2.3 Install ChromeDriver\n",
    "\n",
    "1. Unzip the downloaded file\n",
    "2. Place `chromedriver` (Mac/Linux) or `chromedriver.exe` (Windows) in:\n",
    "   - **Option A**: The same folder as this notebook\n",
    "   - **Option B**: A folder in your system PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Verify Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if Selenium is installed\n",
    "import selenium\n",
    "print(f'Selenium version: {selenium.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Browser Initialization Function\n",
    "\n",
    "This function creates a browser instance that works on both Windows and Mac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_browser(headless=False):\n",
    "    \"\"\"\n",
    "    Create and return a Chrome browser instance.\n",
    "    \n",
    "    Args:\n",
    "        headless: If True, runs browser without GUI (useful for servers)\n",
    "    \n",
    "    Returns:\n",
    "        webdriver.Chrome instance\n",
    "    \"\"\"\n",
    "    from selenium.webdriver.chrome.options import Options\n",
    "    \n",
    "    options = Options()\n",
    "    if headless:\n",
    "        options.add_argument('--headless')\n",
    "        options.add_argument('--no-sandbox')  # Required for some environments\n",
    "        options.add_argument('--disable-dev-shm-usage')  # Overcome limited resource problems\n",
    "    \n",
    "    try:\n",
    "        # Modern Selenium (4.x) - auto-manages drivers\n",
    "        browser = webdriver.Chrome(options=options)\n",
    "    except Exception as e:\n",
    "        print(f'Error starting browser: {e}')\n",
    "        print('\\nTroubleshooting:')\n",
    "        print('1. Make sure Chrome is installed')\n",
    "        print('2. For older Selenium, ensure chromedriver is in PATH or current directory')\n",
    "        raise\n",
    "    \n",
    "    return browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test browser creation\n",
    "print('Starting browser...')\n",
    "browser = get_browser(headless=True)  # Use headless=False to see the browser\n",
    "browser.get('https://quotes.toscrape.com/')\n",
    "print(f'Page title: {browser.title}')\n",
    "browser.quit()\n",
    "print('Browser closed successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Setup Issues and Solutions\n",
    "\n",
    "### Issue 1: \"chromedriver\" cannot be opened (Mac)\n",
    "\n",
    "**Solution**: \n",
    "```bash\n",
    "xattr -d com.apple.quarantine chromedriver\n",
    "```\n",
    "Or: System Preferences > Security & Privacy > Allow anyway\n",
    "\n",
    "### Issue 2: Version mismatch error\n",
    "\n",
    "**Solution**: Download ChromeDriver matching your exact Chrome version\n",
    "\n",
    "### Issue 3: \"str has no capabilities\" error\n",
    "\n",
    "**Solution**: Update to Selenium 4.x which doesn't require executable path:\n",
    "```bash\n",
    "pip install --upgrade selenium\n",
    "```\n",
    "\n",
    "### Issue 4: Browser crashes immediately\n",
    "\n",
    "**Solution**: Try headless mode or add these options:\n",
    "```python\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Selenium Fundamentals\n",
    "\n",
    "## Core Concepts\n",
    "\n",
    "### WebDriver\n",
    "The main interface to control the browser. Think of it as a remote control.\n",
    "\n",
    "### Locating Elements\n",
    "Selenium provides multiple ways to find elements on a page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Elements\n",
    "\n",
    "| Method | Usage | Example |\n",
    "|--------|-------|---------|  \n",
    "| By.ID | Unique element | `By.ID, 'submit-btn'` |\n",
    "| By.CLASS_NAME | Elements with class | `By.CLASS_NAME, 'quote'` |\n",
    "| By.TAG_NAME | HTML tag | `By.TAG_NAME, 'h1'` |\n",
    "| By.CSS_SELECTOR | CSS selector | `By.CSS_SELECTOR, 'div.quote span.text'` |\n",
    "| By.XPATH | XPath expression | `By.XPATH, '//div[@class=\"quote\"]'` |\n",
    "| By.LINK_TEXT | Exact link text | `By.LINK_TEXT, 'Next'` |\n",
    "| By.PARTIAL_LINK_TEXT | Partial link text | `By.PARTIAL_LINK_TEXT, 'Nex'` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Different ways to find elements\n",
    "browser = get_browser(headless=True)\n",
    "browser.get('https://quotes.toscrape.com/')\n",
    "\n",
    "# By tag name\n",
    "title = browser.find_element(By.TAG_NAME, 'h1')\n",
    "print(f'Title (by tag): {title.text}')\n",
    "\n",
    "# By class name\n",
    "first_quote = browser.find_element(By.CLASS_NAME, 'quote')\n",
    "print(f'First quote exists: {first_quote is not None}')\n",
    "\n",
    "# By CSS selector\n",
    "quote_text = browser.find_element(By.CSS_SELECTOR, 'span.text')\n",
    "print(f'Quote text: {quote_text.text[:50]}...')\n",
    "\n",
    "# By XPath\n",
    "author = browser.find_element(By.XPATH, '//small[@class=\"author\"]')\n",
    "print(f'Author: {author.text}')\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single vs Multiple Elements\n",
    "\n",
    "```python\n",
    "# Single element (first match)\n",
    "element = browser.find_element(By.CLASS_NAME, 'quote')\n",
    "\n",
    "# Multiple elements (list of all matches)\n",
    "elements = browser.find_elements(By.CLASS_NAME, 'quote')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Getting multiple elements\n",
    "browser = get_browser(headless=True)\n",
    "browser.get('https://quotes.toscrape.com/')\n",
    "\n",
    "# Get all quotes\n",
    "quotes = browser.find_elements(By.CLASS_NAME, 'quote')\n",
    "print(f'Found {len(quotes)} quotes on this page')\n",
    "\n",
    "# Extract data from each\n",
    "for i, quote in enumerate(quotes[:3]):  # First 3\n",
    "    text = quote.find_element(By.CLASS_NAME, 'text').text\n",
    "    author = quote.find_element(By.CLASS_NAME, 'author').text\n",
    "    print(f'\\n{i+1}. {text[:60]}...')\n",
    "    print(f'   - {author}')\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waiting for Elements\n",
    "\n",
    "Web pages take time to load. Selenium provides two waiting strategies:\n",
    "\n",
    "### Implicit Wait (Global)\n",
    "Sets a default wait time for all element searches.\n",
    "\n",
    "```python\n",
    "browser.implicitly_wait(10)  # Wait up to 10 seconds\n",
    "```\n",
    "\n",
    "### Explicit Wait (Specific)\n",
    "Wait for specific conditions before proceeding.\n",
    "\n",
    "```python\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "wait = WebDriverWait(browser, 10)\n",
    "element = wait.until(EC.presence_of_element_located((By.ID, 'myid')))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using explicit waits\n",
    "browser = get_browser(headless=True)\n",
    "\n",
    "# Visit a page with JavaScript-loaded content\n",
    "browser.get('https://quotes.toscrape.com/js/')\n",
    "\n",
    "# Wait for quotes to appear (they're loaded by JavaScript)\n",
    "wait = WebDriverWait(browser, 10)\n",
    "try:\n",
    "    quotes = wait.until(\n",
    "        EC.presence_of_all_elements_located((By.CLASS_NAME, 'quote'))\n",
    "    )\n",
    "    print(f'Found {len(quotes)} quotes after waiting')\n",
    "except TimeoutException:\n",
    "    print('Timeout: Quotes did not load in time')\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Clicking and navigating\n",
    "browser = get_browser(headless=True)\n",
    "browser.get('https://quotes.toscrape.com/')\n",
    "\n",
    "print(f'Starting page: {browser.current_url}')\n",
    "\n",
    "# Click the 'Next' link to go to page 2\n",
    "next_link = browser.find_element(By.PARTIAL_LINK_TEXT, 'Next')\n",
    "next_link.click()\n",
    "\n",
    "time.sleep(1)  # Wait for navigation\n",
    "print(f'After clicking Next: {browser.current_url}')\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Filling forms\n",
    "browser = get_browser(headless=True)\n",
    "browser.get('https://quotes.toscrape.com/login')\n",
    "\n",
    "# Find form fields\n",
    "username_field = browser.find_element(By.ID, 'username')\n",
    "password_field = browser.find_element(By.ID, 'password')\n",
    "\n",
    "# Fill in the form\n",
    "username_field.send_keys('test_user')\n",
    "password_field.send_keys('test_password')\n",
    "\n",
    "print('Form filled (not submitting in this example)')\n",
    "\n",
    "# To submit: browser.find_element(By.CSS_SELECTOR, 'input[type=\"submit\"]').click()\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Scrolling the page\n",
    "browser = get_browser(headless=True)\n",
    "browser.get('https://quotes.toscrape.com/')\n",
    "\n",
    "# Method 1: Using Keys\n",
    "body = browser.find_element(By.TAG_NAME, 'body')\n",
    "body.send_keys(Keys.PAGE_DOWN)\n",
    "print('Scrolled down using PAGE_DOWN key')\n",
    "\n",
    "time.sleep(0.5)\n",
    "\n",
    "# Method 2: Using JavaScript\n",
    "browser.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "print('Scrolled to bottom using JavaScript')\n",
    "\n",
    "# Method 3: Scroll by specific amount\n",
    "browser.execute_script('window.scrollBy(0, 500);')\n",
    "print('Scrolled down 500 pixels')\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Practical Example - BBC Weather\n",
    "\n",
    "Let's scrape weather information from BBC Weather, demonstrating real-world Selenium usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_bbc_weather():\n",
    "    \"\"\"\n",
    "    Scrape sunrise time for Edinburgh from BBC Weather.\n",
    "    \n",
    "    This demonstrates:\n",
    "    - Navigating to a page\n",
    "    - Clicking elements\n",
    "    - Waiting for content\n",
    "    - Handling cookies consent\n",
    "    - Extracting specific data\n",
    "    \"\"\"\n",
    "    browser = get_browser(headless=True)\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Go to BBC Weather\n",
    "        print('Step 1: Navigating to BBC Weather...')\n",
    "        browser.get('https://www.bbc.co.uk/weather')\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Step 2: Handle cookies consent (if present)\n",
    "        print('Step 2: Checking for cookies dialog...')\n",
    "        try:\n",
    "            wait = WebDriverWait(browser, 5)\n",
    "            accept_btn = wait.until(\n",
    "                EC.element_to_be_clickable((By.ID, 'bbccookies-continue-button'))\n",
    "            )\n",
    "            accept_btn.click()\n",
    "            print('   Accepted cookies')\n",
    "            time.sleep(1)\n",
    "        except TimeoutException:\n",
    "            print('   No cookies dialog found')\n",
    "        \n",
    "        # Step 3: Click on Edinburgh\n",
    "        print('Step 3: Clicking Edinburgh...')\n",
    "        try:\n",
    "            edinburgh_link = browser.find_element(\n",
    "                By.XPATH, \"//span[text()='Edinburgh']\"\n",
    "            )\n",
    "            edinburgh_link.click()\n",
    "            time.sleep(2)\n",
    "            print('   Navigated to Edinburgh weather')\n",
    "        except NoSuchElementException:\n",
    "            print('   Edinburgh link not found on page')\n",
    "            return None\n",
    "        \n",
    "        # Step 4: Get current page data\n",
    "        print('Step 4: Extracting weather data...')\n",
    "        soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "        \n",
    "        # Try to find sunrise/sunset data\n",
    "        sunrise_elements = soup.find_all('span', {'class': 'wr-c-astro-data__time'})\n",
    "        \n",
    "        if sunrise_elements:\n",
    "            sunrise = sunrise_elements[0].text if len(sunrise_elements) > 0 else 'N/A'\n",
    "            sunset = sunrise_elements[1].text if len(sunrise_elements) > 1 else 'N/A'\n",
    "            print(f'\\nResults for Edinburgh:')\n",
    "            print(f'   Sunrise: {sunrise}')\n",
    "            print(f'   Sunset: {sunset}')\n",
    "            return {'sunrise': sunrise, 'sunset': sunset}\n",
    "        else:\n",
    "            print('   Could not find sunrise/sunset data')\n",
    "            return None\n",
    "            \n",
    "    finally:\n",
    "        browser.quit()\n",
    "        print('\\nBrowser closed.')\n",
    "\n",
    "# Run the scraper\n",
    "# Note: This may not work in all environments due to page structure changes\n",
    "# result = scrape_bbc_weather()\n",
    "print('Run scrape_bbc_weather() to test (may require adjustments for current page structure)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Selenium vs Playwright Comparison\n",
    "\n",
    "Let's do the same task with both tools to see the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELENIUM VERSION\n",
    "def scrape_quotes_selenium():\n",
    "    \"\"\"Scrape quotes using Selenium.\"\"\"\n",
    "    browser = get_browser(headless=True)\n",
    "    quotes_data = []\n",
    "    \n",
    "    try:\n",
    "        browser.get('https://quotes.toscrape.com/js/')\n",
    "        \n",
    "        # Wait for quotes to load\n",
    "        wait = WebDriverWait(browser, 10)\n",
    "        wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'quote')))\n",
    "        \n",
    "        # Extract quotes\n",
    "        quotes = browser.find_elements(By.CLASS_NAME, 'quote')\n",
    "        \n",
    "        for quote in quotes:\n",
    "            text = quote.find_element(By.CLASS_NAME, 'text').text\n",
    "            author = quote.find_element(By.CLASS_NAME, 'author').text\n",
    "            quotes_data.append({'text': text, 'author': author})\n",
    "            \n",
    "    finally:\n",
    "        browser.quit()\n",
    "    \n",
    "    return quotes_data\n",
    "\n",
    "# Test Selenium version\n",
    "print('Selenium version:')\n",
    "start = time.time()\n",
    "selenium_quotes = scrape_quotes_selenium()\n",
    "selenium_time = time.time() - start\n",
    "print(f'Found {len(selenium_quotes)} quotes in {selenium_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLAYWRIGHT VERSION (for comparison)\n",
    "from playwright.sync_api import sync_playwright\n",
    "\n",
    "def scrape_quotes_playwright():\n",
    "    \"\"\"Scrape quotes using Playwright.\"\"\"\n",
    "    quotes_data = []\n",
    "    \n",
    "    with sync_playwright() as p:\n",
    "        browser = p.chromium.launch(headless=True)\n",
    "        page = browser.new_page()\n",
    "        \n",
    "        page.goto('https://quotes.toscrape.com/js/')\n",
    "        page.wait_for_selector('.quote')\n",
    "        \n",
    "        # Get HTML and parse with BeautifulSoup\n",
    "        soup = BeautifulSoup(page.content(), 'html.parser')\n",
    "        quotes = soup.find_all('div', {'class': 'quote'})\n",
    "        \n",
    "        for quote in quotes:\n",
    "            text = quote.find('span', {'class': 'text'}).text\n",
    "            author = quote.find('small', {'class': 'author'}).text\n",
    "            quotes_data.append({'text': text, 'author': author})\n",
    "        \n",
    "        browser.close()\n",
    "    \n",
    "    return quotes_data\n",
    "\n",
    "# Test Playwright version\n",
    "print('\\nPlaywright version:')\n",
    "start = time.time()\n",
    "playwright_quotes = scrape_quotes_playwright()\n",
    "playwright_time = time.time() - start\n",
    "print(f'Found {len(playwright_quotes)} quotes in {playwright_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "print('\\n--- Comparison ---')\n",
    "print(f'Selenium: {selenium_time:.2f}s')\n",
    "print(f'Playwright: {playwright_time:.2f}s')\n",
    "print(f'Both found same number of quotes: {len(selenium_quotes) == len(playwright_quotes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Syntax Differences\n",
    "\n",
    "| Task | Selenium | Playwright |\n",
    "|------|----------|------------|\n",
    "| Launch | `webdriver.Chrome()` | `p.chromium.launch()` |\n",
    "| Navigate | `browser.get(url)` | `page.goto(url)` |\n",
    "| Find one | `browser.find_element(By.X, val)` | `page.query_selector(sel)` |\n",
    "| Find all | `browser.find_elements(By.X, val)` | `page.query_selector_all(sel)` |\n",
    "| Wait | `WebDriverWait(...).until(...)` | `page.wait_for_selector(sel)` |\n",
    "| Click | `element.click()` | `page.click(sel)` |\n",
    "| Get HTML | `browser.page_source` | `page.content()` |\n",
    "| Close | `browser.quit()` | `browser.close()` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: XPath Basics\n",
    "\n",
    "XPath is a powerful way to locate elements. Here are common patterns:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common XPath Patterns\n",
    "\n",
    "```xpath\n",
    "# By tag\n",
    "//div                  # All div elements\n",
    "//div/p                # p elements that are direct children of div\n",
    "//div//p               # p elements anywhere inside div\n",
    "\n",
    "# By attribute\n",
    "//div[@id='main']      # div with id=\"main\"\n",
    "//div[@class='card']   # div with class=\"card\"\n",
    "//a[@href]             # All links with href attribute\n",
    "\n",
    "# By text content\n",
    "//span[text()='Hello']           # span containing exact text\n",
    "//span[contains(text(),'Hello')] # span containing text\n",
    "\n",
    "# Position\n",
    "//div[1]               # First div\n",
    "//div[last()]          # Last div\n",
    "//div[position()<=3]   # First 3 divs\n",
    "\n",
    "# Combining\n",
    "//div[@class='quote']//span[@class='text']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XPath examples\n",
    "browser = get_browser(headless=True)\n",
    "browser.get('https://quotes.toscrape.com/')\n",
    "\n",
    "# Find first quote text\n",
    "first_quote = browser.find_element(By.XPATH, '//span[@class=\"text\"]')\n",
    "print(f'First quote: {first_quote.text[:50]}...')\n",
    "\n",
    "# Find all authors\n",
    "authors = browser.find_elements(By.XPATH, '//small[@class=\"author\"]')\n",
    "print(f'\\nAuthors on page: {[a.text for a in authors[:5]]}')\n",
    "\n",
    "# Find quote containing specific text\n",
    "einstein_quote = browser.find_element(\n",
    "    By.XPATH, '//div[@class=\"quote\"][.//small[text()=\"Albert Einstein\"]]//span[@class=\"text\"]'\n",
    ")\n",
    "print(f'\\nEinstein quote: {einstein_quote.text[:50]}...')\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding XPath in Browser\n",
    "\n",
    "1. Right-click on element > Inspect\n",
    "2. In DevTools, right-click the HTML > Copy > Copy XPath\n",
    "\n",
    "**Note**: Auto-generated XPaths can be brittle. It's often better to write your own based on stable attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "## When to Use Selenium\n",
    "\n",
    "- Working with existing Selenium codebases\n",
    "- Need to support browsers beyond Chrome/Firefox/Safari\n",
    "- Team already knows Selenium\n",
    "- Following tutorials/courses that use Selenium\n",
    "\n",
    "## Key Selenium Concepts\n",
    "\n",
    "1. **WebDriver**: The browser controller\n",
    "2. **Locators**: By.ID, By.CLASS_NAME, By.XPATH, By.CSS_SELECTOR\n",
    "3. **Waits**: Implicit (global) and Explicit (specific)\n",
    "4. **Actions**: click(), send_keys(), execute_script()\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "- Use explicit waits instead of `time.sleep()` where possible\n",
    "- Always close the browser in a `finally` block\n",
    "- Use headless mode for automation\n",
    "- Handle exceptions gracefully\n",
    "- Prefer stable locators (ID > class > XPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*End of Optional Selenium Notebook*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
