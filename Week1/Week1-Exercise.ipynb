{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1: Exercises\n",
    "\n",
    "**Web and Social Network Analytics**\n",
    "\n",
    "---\n",
    "\n",
    "Complete these exercises to practice web scraping techniques covered in the lecture notes.\n",
    "\n",
    "**Disclaimer**: This educational content is provided for instructional purposes only. Always respect website terms of service and legal requirements when scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "Run the cell below to import all required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Web scraping\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "\n",
    "# For dynamic scraping (Exercise 3)\n",
    "# from playwright.sync_api import sync_playwright\n",
    "\n",
    "print('Libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Exercise 1: BeautifulSoup Basics (Easy)\n",
    "\n",
    "## Task\n",
    "\n",
    "Extract the **SCQF Level** from a course page on the University of Edinburgh's DRPS website.\n",
    "\n",
    "**URL**: `http://www.drps.ed.ac.uk/24-25/dpt/cxcmse11427.htm`\n",
    "\n",
    "**Expected Output**: The cell containing text like \"SCQF Level 11\"\n",
    "\n",
    "## Skills Practiced\n",
    "- Fetching web pages with `urlopen`\n",
    "- Parsing HTML with BeautifulSoup\n",
    "- Finding elements by tag and class\n",
    "- Searching for specific text content\n",
    "\n",
    "## Hints\n",
    "\n",
    "<details>\n",
    "<summary>Hint 1: How to fetch the page</summary>\n",
    "\n",
    "```python\n",
    "url = 'http://www.drps.ed.ac.uk/24-25/dpt/cxcmse11427.htm'\n",
    "html = urlopen(url)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Hint 2: Finding the table</summary>\n",
    "\n",
    "The SCQF information is in a table with class `sitstablegrid`. Use:\n",
    "```python\n",
    "table = soup.find('table', {'class': 'sitstablegrid'})\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Hint 3: Searching for text</summary>\n",
    "\n",
    "Loop through cells and check if 'SCQF' is in the text:\n",
    "```python\n",
    "for cell in table.find_all('td'):\n",
    "    if 'SCQF' in cell.text:\n",
    "        # Found it!\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Your code here\n",
    "\n",
    "# Step 1: Fetch the page\n",
    "url = 'http://www.drps.ed.ac.uk/24-25/dpt/cxcmse11427.htm'\n",
    "\n",
    "# Your code below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Exercise 2: Multi-Item Scraping (Medium)\n",
    "\n",
    "## Task\n",
    "\n",
    "Scrape quotes from **quotes.toscrape.com** and create a pandas DataFrame.\n",
    "\n",
    "**Requirements**:\n",
    "1. Scrape the **first 3 pages** of quotes\n",
    "2. For each quote, extract:\n",
    "   - The quote text\n",
    "   - The author name\n",
    "   - The tags (as a list)\n",
    "3. Store in a DataFrame with columns: `text`, `author`, `tags`\n",
    "4. Add a 1-second delay between page requests\n",
    "\n",
    "**Expected**: A DataFrame with ~30 quotes (10 per page)\n",
    "\n",
    "## Skills Practiced\n",
    "- Handling pagination\n",
    "- Extracting multiple data points\n",
    "- Building structured datasets\n",
    "- Respectful scraping with delays\n",
    "\n",
    "## Hints\n",
    "\n",
    "<details>\n",
    "<summary>Hint 1: URL pattern for pagination</summary>\n",
    "\n",
    "Pages follow the pattern:\n",
    "- Page 1: `https://quotes.toscrape.com/page/1/`\n",
    "- Page 2: `https://quotes.toscrape.com/page/2/`\n",
    "- etc.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Hint 2: Finding quote elements</summary>\n",
    "\n",
    "Each quote is in a `div` with class `quote`:\n",
    "- Text: `span` with class `text`\n",
    "- Author: `small` with class `author`\n",
    "- Tags: `a` elements with class `tag`\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Hint 3: Getting tags as a list</summary>\n",
    "\n",
    "```python\n",
    "tags = [tag.text for tag in quote.find_all('a', {'class': 'tag'})]\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Your code here\n",
    "\n",
    "all_quotes = []\n",
    "\n",
    "# Loop through pages 1 to 3\n",
    "for page_num in range(1, 4):\n",
    "    url = f'https://quotes.toscrape.com/page/{page_num}/'\n",
    "    print(f'Scraping page {page_num}...')\n",
    "    \n",
    "    # Your code below:\n",
    "    \n",
    "    \n",
    "    # Don't forget to add a delay!\n",
    "\n",
    "# Create DataFrame\n",
    "# df = pd.DataFrame(all_quotes)\n",
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display your results\n",
    "# print(f'Total quotes: {len(df)}')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Exercise 3: Dynamic Content with Playwright (Medium)\n",
    "\n",
    "## Task\n",
    "\n",
    "Scrape quotes from the **JavaScript-rendered** version of the quotes website: `https://quotes.toscrape.com/js/`\n",
    "\n",
    "**Requirements**:\n",
    "1. Use Playwright to render the JavaScript content\n",
    "2. Extract all quotes from the first page\n",
    "3. Create a DataFrame with `text` and `author` columns\n",
    "\n",
    "**Why is this different?**\n",
    "The `/js/` version loads quotes using JavaScript. BeautifulSoup alone won't see them!\n",
    "\n",
    "## Skills Practiced\n",
    "- Setting up Playwright\n",
    "- Waiting for dynamic content\n",
    "- Combining Playwright with BeautifulSoup\n",
    "\n",
    "## Hints\n",
    "\n",
    "<details>\n",
    "<summary>Hint 1: Setup Playwright</summary>\n",
    "\n",
    "```python\n",
    "# Install if needed:\n",
    "# !pip install playwright\n",
    "# !playwright install chromium\n",
    "\n",
    "from playwright.sync_api import sync_playwright\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Hint 2: Basic Playwright pattern</summary>\n",
    "\n",
    "```python\n",
    "with sync_playwright() as p:\n",
    "    browser = p.chromium.launch(headless=True)\n",
    "    page = browser.new_page()\n",
    "    page.goto(url)\n",
    "    page.wait_for_selector('.quote')  # Wait for content\n",
    "    html = page.content()\n",
    "    browser.close()\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Hint 3: Then use BeautifulSoup</summary>\n",
    "\n",
    "After getting the HTML from Playwright:\n",
    "```python\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "quotes = soup.find_all('div', {'class': 'quote'})\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Setup\n",
    "# Uncomment these lines if you haven't installed Playwright yet:\n",
    "# !pip install playwright\n",
    "# !playwright install chromium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Your code here\n",
    "\n",
    "from playwright.sync_api import sync_playwright\n",
    "\n",
    "url = 'https://quotes.toscrape.com/js/'\n",
    "\n",
    "# Your code below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display your results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Exercise 4: API Data Retrieval (Easy-Medium)\n",
    "\n",
    "## Task A: Weather API (Required)\n",
    "\n",
    "Use the **Open-Meteo API** to get current weather for 3 Scottish cities.\n",
    "\n",
    "**Cities and coordinates**:\n",
    "- Edinburgh: (55.95, -3.19)\n",
    "- Glasgow: (55.86, -4.25)\n",
    "- Aberdeen: (57.15, -2.11)\n",
    "\n",
    "**Requirements**:\n",
    "1. Fetch current weather for each city\n",
    "2. Extract temperature and wind speed\n",
    "3. Create a DataFrame with columns: `city`, `temperature`, `windspeed`\n",
    "\n",
    "## Skills Practiced\n",
    "- Making API requests\n",
    "- Parsing JSON responses\n",
    "- Working with API parameters\n",
    "\n",
    "## Hints\n",
    "\n",
    "<details>\n",
    "<summary>Hint 1: API endpoint and parameters</summary>\n",
    "\n",
    "```python\n",
    "url = 'https://api.open-meteo.com/v1/forecast'\n",
    "params = {\n",
    "    'latitude': 55.95,\n",
    "    'longitude': -3.19,\n",
    "    'current_weather': True\n",
    "}\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Hint 2: Making the request</summary>\n",
    "\n",
    "```python\n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Hint 3: Accessing weather data</summary>\n",
    "\n",
    "```python\n",
    "temperature = data['current_weather']['temperature']\n",
    "windspeed = data['current_weather']['windspeed']\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4A: Your code here\n",
    "\n",
    "import requests\n",
    "\n",
    "cities = {\n",
    "    'Edinburgh': (55.95, -3.19),\n",
    "    'Glasgow': (55.86, -4.25),\n",
    "    'Aberdeen': (57.15, -2.11)\n",
    "}\n",
    "\n",
    "weather_data = []\n",
    "\n",
    "# Your code below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display your results\n",
    "# weather_df = pd.DataFrame(weather_data)\n",
    "# weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B: Google Maps API (Optional - Advanced)\n",
    "\n",
    "If you have a Google Cloud API key, try to fetch place details.\n",
    "\n",
    "**Note**: This requires setting up Google Cloud Platform and enabling the Places API.\n",
    "\n",
    "**Task**:\n",
    "1. Get details for \"Edinburgh Castle\" \n",
    "2. Extract the rating and number of reviews\n",
    "3. Print the first 3 reviews (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4B (Optional): Your code here\n",
    "\n",
    "# api_key = 'YOUR_API_KEY_HERE'  # Replace with your key\n",
    "\n",
    "# Your code below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Bonus Challenge\n",
    "\n",
    "## Task: Combine Multiple Techniques\n",
    "\n",
    "Create a function that:\n",
    "1. Takes a city name as input\n",
    "2. Uses Open-Meteo API to get current weather\n",
    "3. Uses web scraping to get additional info (your choice of source)\n",
    "4. Returns a dictionary with combined information\n",
    "\n",
    "**This is open-ended** - be creative!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus Challenge: Your code here\n",
    "\n",
    "def get_city_info(city_name, latitude, longitude):\n",
    "    \"\"\"\n",
    "    Get comprehensive information about a city.\n",
    "    \n",
    "    Args:\n",
    "        city_name: Name of the city\n",
    "        latitude: City latitude\n",
    "        longitude: City longitude\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with city information\n",
    "    \"\"\"\n",
    "    info = {'city': city_name}\n",
    "    \n",
    "    # Your code below:\n",
    "    \n",
    "    return info\n",
    "\n",
    "# Test your function\n",
    "# result = get_city_info('Edinburgh', 55.95, -3.19)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Submission Checklist\n",
    "\n",
    "Before submitting, make sure:\n",
    "\n",
    "- [ ] Exercise 1 outputs the SCQF level\n",
    "- [ ] Exercise 2 produces a DataFrame with ~30 quotes\n",
    "- [ ] Exercise 3 successfully scrapes the JS-rendered page\n",
    "- [ ] Exercise 4A shows weather for 3 cities\n",
    "- [ ] All code cells run without errors\n",
    "- [ ] You've added comments explaining your approach\n",
    "\n",
    "---\n",
    "\n",
    "*See Week1-Exercise-Solutions.ipynb for complete solutions*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
