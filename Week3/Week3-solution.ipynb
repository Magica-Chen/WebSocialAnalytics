{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3: Exercise Solutions - Social Media & Graph Analytics\n",
    "\n",
    "**Web and Social Network Analytics**\n",
    "\n",
    "---\n",
    "\n",
    "This notebook contains complete solutions for all Week 3 exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Graph analysis\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "from networkx.algorithms.community import kernighan_lin_bisection\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import pprint as pp\n",
    "\n",
    "print('All libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 1 Solution: Building a Social Network Graph\n",
    "\n",
    "**Task**: Create a directed graph representing Twitter follows between 6 users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Step 2: Add edges representing follows (at least 8 edges)\n",
    "# alice follows bob, carol, dave\n",
    "# bob follows alice (mutual), carol\n",
    "# carol follows dave, eve\n",
    "# dave follows eve, frank\n",
    "# eve follows frank\n",
    "# frank follows alice\n",
    "\n",
    "G.add_edges_from([\n",
    "    ('alice', 'bob'),\n",
    "    ('alice', 'carol'),\n",
    "    ('alice', 'dave'),\n",
    "    ('bob', 'alice'),      # Mutual follow with alice\n",
    "    ('bob', 'carol'),\n",
    "    ('carol', 'dave'),\n",
    "    ('carol', 'eve'),\n",
    "    ('dave', 'eve'),\n",
    "    ('dave', 'frank'),\n",
    "    ('eve', 'frank'),\n",
    "    ('frank', 'alice')     # Creates a cycle back to alice\n",
    "])\n",
    "\n",
    "# Step 3: Print basic statistics\n",
    "print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {G.number_of_edges()}\")\n",
    "print(f\"\\nNodes: {list(G.nodes())}\")\n",
    "print(f\"\\nEdges (who follows whom):\")\n",
    "for u, v in G.edges():\n",
    "    print(f\"  {u} follows {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Visualize the graph\n",
    "pos = nx.spring_layout(G, seed=2000)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "nx.draw(G, pos, with_labels=True, node_size=2000, node_color='lightblue',\n",
    "        font_size=12, font_weight='bold', arrows=True, arrowsize=20,\n",
    "        edge_color='gray', width=2)\n",
    "plt.title(\"Twitter Follows Network\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional analysis: In-degree vs Out-degree\n",
    "print(\"\\nIn-degree (followers) vs Out-degree (following):\")\n",
    "print(\"-\" * 50)\n",
    "for node in G.nodes():\n",
    "    print(f\"{node:10} | in-degree: {G.in_degree(node):2} | out-degree: {G.out_degree(node):2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Points:**\n",
    "- The graph has 6 nodes and 11 edges\n",
    "- Alice and Bob have a mutual follow relationship\n",
    "- There's a cycle: alice -> dave -> frank -> alice\n",
    "- In directed graphs, in-degree = followers, out-degree = following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 2 Solution: Calculating Centrality Measures\n",
    "\n",
    "**Task**: Calculate degree and betweenness centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate degree centrality\n",
    "degree = nx.degree_centrality(G)\n",
    "\n",
    "print(\"Degree Centrality (normalized by max possible connections):\")\n",
    "print(\"-\" * 50)\n",
    "for node, value in sorted(degree.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{node:10}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Calculate betweenness centrality\n",
    "betweenness = nx.betweenness_centrality(G)\n",
    "\n",
    "print(\"Betweenness Centrality (how often node is on shortest paths):\")\n",
    "print(\"-\" * 50)\n",
    "for node, value in sorted(betweenness.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{node:10}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Find and print the most central nodes\n",
    "max_degree_node = max(degree, key=degree.get)\n",
    "max_betweenness_node = max(betweenness, key=betweenness.get)\n",
    "\n",
    "print(f\"Most central by degree: {max_degree_node} (score: {degree[max_degree_node]:.3f})\")\n",
    "print(f\"Most central by betweenness: {max_betweenness_node} (score: {betweenness[max_betweenness_node]:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Visualize with node sizes based on degree centrality\n",
    "sizes = [degree[node] * 3000 for node in G.nodes()]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "nx.draw(G, pos, with_labels=True, node_size=sizes, node_color='lightcoral',\n",
    "        font_size=12, arrows=True, arrowsize=15, width=2)\n",
    "plt.title(\"Node Size = Degree Centrality\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize with betweenness centrality\n",
    "sizes_betweenness = [max(betweenness[node] * 5000, 200) for node in G.nodes()]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "nx.draw(G, pos, with_labels=True, node_size=sizes_betweenness, node_color='lightgreen',\n",
    "        font_size=12, arrows=True, arrowsize=15, width=2)\n",
    "plt.title(\"Node Size = Betweenness Centrality\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Points:**\n",
    "- Degree centrality measures total connections (in + out in directed graphs)\n",
    "- Betweenness centrality measures how often a node acts as a bridge\n",
    "- These measures can give different rankings for \"importance\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 3 Solution: Clustering Coefficient Calculation\n",
    "\n",
    "**Task**: Calculate clustering coefficients by hand and verify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create the undirected graph\n",
    "G_cluster = nx.Graph()\n",
    "G_cluster.add_edges_from([\n",
    "    ('A', 'B'), ('A', 'C'), ('A', 'D'),\n",
    "    ('B', 'C'),\n",
    "    ('C', 'D'),\n",
    "    ('D', 'E')\n",
    "])\n",
    "\n",
    "# Step 2: Visualize\n",
    "pos_cluster = nx.spring_layout(G_cluster, seed=42)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "nx.draw(G_cluster, pos_cluster, with_labels=True, node_size=1500, \n",
    "        node_color='lightblue', font_size=14, font_weight='bold', width=2)\n",
    "plt.title(\"Graph for Clustering Coefficient Calculation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Hand calculation for node A\n",
    "print(\"=\" * 50)\n",
    "print(\"HAND CALCULATION FOR NODE A\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "neighbors_A = list(G_cluster.neighbors('A'))\n",
    "print(f\"1. Neighbors of A: {neighbors_A}\")\n",
    "print(f\"2. Degree of A (k): {len(neighbors_A)}\")\n",
    "\n",
    "# Count edges between neighbors\n",
    "edges_between_neighbors = 0\n",
    "neighbor_pairs = []\n",
    "for i, n1 in enumerate(neighbors_A):\n",
    "    for n2 in neighbors_A[i+1:]:\n",
    "        neighbor_pairs.append((n1, n2))\n",
    "        if G_cluster.has_edge(n1, n2):\n",
    "            edges_between_neighbors += 1\n",
    "            print(f\"   Edge found: {n1}-{n2}\")\n",
    "        else:\n",
    "            print(f\"   No edge: {n1}-{n2}\")\n",
    "\n",
    "print(f\"3. Edges between neighbors: {edges_between_neighbors}\")\n",
    "\n",
    "k = len(neighbors_A)\n",
    "max_edges = k * (k - 1) // 2\n",
    "print(f\"4. Maximum possible edges: k(k-1)/2 = {k}*{k-1}/2 = {max_edges}\")\n",
    "\n",
    "clustering_A = edges_between_neighbors / max_edges if max_edges > 0 else 0\n",
    "print(f\"5. Clustering coefficient: {edges_between_neighbors}/{max_edges} = {clustering_A:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Hand calculation for node D\n",
    "print(\"=\" * 50)\n",
    "print(\"HAND CALCULATION FOR NODE D\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "neighbors_D = list(G_cluster.neighbors('D'))\n",
    "print(f\"1. Neighbors of D: {neighbors_D}\")\n",
    "print(f\"2. Degree of D (k): {len(neighbors_D)}\")\n",
    "\n",
    "# Count edges between neighbors\n",
    "edges_D = 0\n",
    "for i, n1 in enumerate(neighbors_D):\n",
    "    for n2 in neighbors_D[i+1:]:\n",
    "        if G_cluster.has_edge(n1, n2):\n",
    "            edges_D += 1\n",
    "            print(f\"   Edge found: {n1}-{n2}\")\n",
    "        else:\n",
    "            print(f\"   No edge: {n1}-{n2}\")\n",
    "\n",
    "print(f\"3. Edges between neighbors: {edges_D}\")\n",
    "\n",
    "k_D = len(neighbors_D)\n",
    "max_edges_D = k_D * (k_D - 1) // 2\n",
    "print(f\"4. Maximum possible edges: {k_D}*{k_D-1}/2 = {max_edges_D}\")\n",
    "\n",
    "clustering_D = edges_D / max_edges_D if max_edges_D > 0 else 0\n",
    "print(f\"5. Clustering coefficient: {edges_D}/{max_edges_D} = {clustering_D:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Verify with NetworkX\n",
    "print(\"=\" * 50)\n",
    "print(\"NETWORKX VERIFICATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "clustering_all = nx.clustering(G_cluster)\n",
    "\n",
    "for node, coeff in clustering_all.items():\n",
    "    print(f\"Clustering({node}): {coeff:.3f}\")\n",
    "\n",
    "print(f\"\\nHand calculation for A: {clustering_A:.3f} vs NetworkX: {clustering_all['A']:.3f} - {'MATCH!' if abs(clustering_A - clustering_all['A']) < 0.001 else 'MISMATCH!'}\")\n",
    "print(f\"Hand calculation for D: {clustering_D:.3f} vs NetworkX: {clustering_all['D']:.3f} - {'MATCH!' if abs(clustering_D - clustering_all['D']) < 0.001 else 'MISMATCH!'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Calculate average clustering coefficient\n",
    "avg_clustering = nx.average_clustering(G_cluster)\n",
    "print(f\"\\nAverage Clustering Coefficient: {avg_clustering:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Points:**\n",
    "- Node A has clustering 0.667: 2 out of 3 possible neighbor connections exist\n",
    "- Node D has clustering 0.333: 1 out of 3 possible neighbor connections exist\n",
    "- Node E has clustering 0.0: only one neighbor, no triangle possible\n",
    "- Higher clustering = friends know each other (tight-knit group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 4 Solution: Community Detection with Kernighan-Lin\n",
    "\n",
    "**Task**: Apply Kernighan-Lin algorithm to partition a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create graph with two communities\n",
    "G_community = nx.Graph()\n",
    "\n",
    "# Community 1: A, B, C, D (densely connected - complete subgraph)\n",
    "G_community.add_edges_from([\n",
    "    ('A', 'B'), ('A', 'C'), ('A', 'D'),\n",
    "    ('B', 'C'), ('B', 'D'),\n",
    "    ('C', 'D')\n",
    "])\n",
    "\n",
    "# Community 2: E, F, G, H (densely connected - complete subgraph)\n",
    "G_community.add_edges_from([\n",
    "    ('E', 'F'), ('E', 'G'), ('E', 'H'),\n",
    "    ('F', 'G'), ('F', 'H'),\n",
    "    ('G', 'H')\n",
    "])\n",
    "\n",
    "# Bridge edges between communities (sparse)\n",
    "G_community.add_edges_from([\n",
    "    ('D', 'E'),  # One bridge\n",
    "    ('C', 'F')   # Another bridge\n",
    "])\n",
    "\n",
    "print(f\"Graph has {G_community.number_of_nodes()} nodes and {G_community.number_of_edges()} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Visualize the original graph\n",
    "pos_comm = nx.spring_layout(G_community, seed=42)\n",
    "\n",
    "# Color by original communities\n",
    "original_set1 = {'A', 'B', 'C', 'D'}\n",
    "original_set2 = {'E', 'F', 'G', 'H'}\n",
    "colors = ['lightblue' if node in original_set1 else 'lightgreen' \n",
    "          for node in G_community.nodes()]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "nx.draw(G_community, pos_comm, with_labels=True, node_size=2000, \n",
    "        node_color=colors, font_size=14, font_weight='bold', width=2)\n",
    "plt.title(\"Original Communities: Blue (A-D) vs Green (E-H)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Calculate original cut size\n",
    "original_cut = nx.cut_size(G_community, original_set1, original_set2)\n",
    "print(f\"Original partition cut size: {original_cut}\")\n",
    "print(f\"  (Number of edges between set1 and set2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Apply Kernighan-Lin bisection\n",
    "partition = kernighan_lin_bisection(G_community)\n",
    "partition1, partition2 = partition\n",
    "\n",
    "print(f\"Kernighan-Lin Results:\")\n",
    "print(f\"  Partition 1: {partition1}\")\n",
    "print(f\"  Partition 2: {partition2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Compare results\n",
    "kl_cut = nx.cut_size(G_community, partition1, partition2)\n",
    "\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"  Original partition cut: {original_cut}\")\n",
    "print(f\"  Kernighan-Lin cut: {kl_cut}\")\n",
    "\n",
    "if kl_cut < original_cut:\n",
    "    print(f\"  Kernighan-Lin found a BETTER partition!\")\n",
    "elif kl_cut == original_cut:\n",
    "    print(f\"  Kernighan-Lin found an EQUAL partition.\")\n",
    "else:\n",
    "    print(f\"  Original partition was better.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Visualize Kernighan-Lin partition\n",
    "colors_kl = ['lightblue' if node in partition1 else 'lightgreen' \n",
    "             for node in G_community.nodes()]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "nx.draw(G_community, pos_comm, with_labels=True, node_size=2000, \n",
    "        node_color=colors_kl, font_size=14, font_weight='bold', width=2)\n",
    "plt.title(f\"Kernighan-Lin Partition (Cut Size: {kl_cut})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Points:**\n",
    "- The original partition (A-D vs E-H) has cut size 2 (edges D-E and C-F)\n",
    "- Kernighan-Lin should find this same partition since it's optimal\n",
    "- The algorithm minimizes edges between partitions while balancing partition sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 5 Solution: Analyzing Student Network Data\n",
    "\n",
    "**Task**: Load and analyze the student familiarity network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the data\n",
    "df = pd.read_csv('data/graph_large.csv', index_col=0)\n",
    "\n",
    "# Get column information\n",
    "col_names = list(df.columns)\n",
    "personality_questions = col_names[:10]\n",
    "people = col_names[-30:]\n",
    "experiences_questions = col_names[10:-30]\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Number of personality questions: {len(personality_questions)}\")\n",
    "print(f\"Number of experience questions: {len(experiences_questions)}\")\n",
    "print(f\"Number of students: {len(people)}\")\n",
    "print(f\"\\nStudent IDs: {people[:5]}... (showing first 5)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Build the directed graph (edges with weight > 3)\n",
    "DG = nx.DiGraph()\n",
    "\n",
    "for row, row_values in df.iterrows():\n",
    "    for column, value in enumerate(row_values):\n",
    "        col_name = df.columns[column]\n",
    "        # Only include if it's a person column and value > 3\n",
    "        if col_name in people and value > 3:\n",
    "            DG.add_edge(row, col_name, weight=value)\n",
    "\n",
    "print(f\"Graph created:\")\n",
    "print(f\"  Nodes: {DG.number_of_nodes()}\")\n",
    "print(f\"  Edges: {DG.number_of_edges()}\")\n",
    "print(f\"  Density: {nx.density(DG):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Calculate all centrality measures\n",
    "degree = nx.degree_centrality(DG)\n",
    "betweenness = nx.betweenness_centrality(DG)\n",
    "pagerank = nx.pagerank(DG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Print top 5 by each measure\n",
    "def print_top_5(measure_dict, name):\n",
    "    \"\"\"Print top 5 nodes by a centrality measure.\"\"\"\n",
    "    sorted_items = sorted(measure_dict.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"Top 5 by {name}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    for rank, (node, score) in enumerate(sorted_items, 1):\n",
    "        print(f\"  {rank}. {node}: {score:.4f}\")\n",
    "\n",
    "print_top_5(degree, \"Degree Centrality\")\n",
    "print_top_5(betweenness, \"Betweenness Centrality\")\n",
    "print_top_5(pagerank, \"PageRank\")\n",
    "print_top_5(hubs, \"Hub Score\")\n",
    "print_top_5(authorities, \"Authority Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive comparison table\n",
    "comparison_data = []\n",
    "for node in DG.nodes():\n",
    "    comparison_data.append({\n",
    "        'Student': node,\n",
    "        'Degree': round(degree[node], 4),\n",
    "        'Betweenness': round(betweenness[node], 4),\n",
    "        'PageRank': round(pagerank[node], 4),\n",
    "        'Hub': round(hubs[node], 4),\n",
    "        'Authority': round(authorities[node], 4)\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('PageRank', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Students by PageRank (with all measures):\")\n",
    "print(comparison_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Visualize with PageRank-based node sizes\n",
    "plt.figure(figsize=(14, 12))\n",
    "\n",
    "pos = nx.spring_layout(DG, seed=42)\n",
    "\n",
    "# Scale sizes by PageRank\n",
    "sizes = [pagerank[node] * 10000 for node in DG.nodes()]\n",
    "\n",
    "nx.draw(DG, pos, with_labels=True, node_size=sizes, node_color='lightcoral',\n",
    "        font_size=8, arrows=True, arrowsize=10, width=0.5, alpha=0.7)\n",
    "plt.title(\"Student Network - Node Size = PageRank\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:**\n",
    "\n",
    "1. **Which students appear most \"important\"?**\n",
    "   - The top students by PageRank tend to be those who are well-known by many others who are themselves well-known\n",
    "   - Different measures can highlight different students because they measure different aspects of importance\n",
    "\n",
    "2. **Why might degree and betweenness give different rankings?**\n",
    "   - **Degree centrality** measures how many connections a student has (popularity)\n",
    "   - **Betweenness centrality** measures how often a student is a bridge between others\n",
    "   - A student can be very popular but not be a bridge (everyone in their group knows each other)\n",
    "   - A student can be a critical bridge with fewer direct connections\n",
    "\n",
    "3. **Hub vs Authority in this context:**\n",
    "   - **High hub score**: Student who knows many well-connected students (a social connector)\n",
    "   - **High authority score**: Student who is known by many social connectors (well-respected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bonus Solution: Triadic Closure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_potential_connections(G, min_common_neighbors=2):\n",
    "    \"\"\"\n",
    "    Find pairs of nodes that might become connected via triadic closure.\n",
    "    \n",
    "    Args:\n",
    "        G: NetworkX graph (undirected)\n",
    "        min_common_neighbors: Minimum common neighbors to consider\n",
    "        \n",
    "    Returns:\n",
    "        List of tuples: (node1, node2, num_common_neighbors)\n",
    "    \"\"\"\n",
    "    potential = []\n",
    "    nodes = list(G.nodes())\n",
    "    \n",
    "    for i, node1 in enumerate(nodes):\n",
    "        for node2 in nodes[i+1:]:\n",
    "            # Skip if already connected\n",
    "            if G.has_edge(node1, node2):\n",
    "                continue\n",
    "            \n",
    "            # Find common neighbors\n",
    "            neighbors1 = set(G.neighbors(node1))\n",
    "            neighbors2 = set(G.neighbors(node2))\n",
    "            common = neighbors1 & neighbors2\n",
    "            \n",
    "            if len(common) >= min_common_neighbors:\n",
    "                potential.append((node1, node2, len(common)))\n",
    "    \n",
    "    # Sort by number of common neighbors (descending)\n",
    "    potential.sort(key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    return potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with the student network (convert to undirected)\n",
    "G_undirected = DG.to_undirected()\n",
    "\n",
    "potential_connections = find_potential_connections(G_undirected, min_common_neighbors=2)\n",
    "\n",
    "print(f\"Found {len(potential_connections)} potential connections via triadic closure\")\n",
    "print(f\"\\nTop 10 potential connections:\")\n",
    "print(\"-\" * 50)\n",
    "for node1, node2, common in potential_connections[:10]:\n",
    "    print(f\"{node1} - {node2}: {common} common neighbors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Point**: Triadic closure predicts that students with many mutual friends are likely to become connected. This is the basis for \"People You May Know\" features in social networks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
